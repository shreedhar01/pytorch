{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP9VnLh/VFpoxOsH94lEWBR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"e27c0853a2014507b0457678bf8c0e5e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c6e10582d90d48e9b2fad185e7f83950","IPY_MODEL_bb6cbfe3090b496daf921a4f3ec21ede","IPY_MODEL_3cdfce23167b413295333983f36a5691"],"layout":"IPY_MODEL_ef64508ea2fb479b8772047c07104019"}},"c6e10582d90d48e9b2fad185e7f83950":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0bbdb00cbf734414b6d6c3a2722b54c5","placeholder":"​","style":"IPY_MODEL_c78188b1cc234641ba1ecddabc2d6d36","value":"100%"}},"bb6cbfe3090b496daf921a4f3ec21ede":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a76524cb7944646a4778887e4b531f0","max":5,"min":0,"orientation":"horizontal","style":"IPY_MODEL_58efe5116f634f95bc34df834569063e","value":5}},"3cdfce23167b413295333983f36a5691":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf9df38da63248c0af1118b10303d2f0","placeholder":"​","style":"IPY_MODEL_007f44c18dea4ee192d178d1b86fa098","value":" 5/5 [00:05&lt;00:00,  1.07it/s]"}},"ef64508ea2fb479b8772047c07104019":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0bbdb00cbf734414b6d6c3a2722b54c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c78188b1cc234641ba1ecddabc2d6d36":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0a76524cb7944646a4778887e4b531f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58efe5116f634f95bc34df834569063e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cf9df38da63248c0af1118b10303d2f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"007f44c18dea4ee192d178d1b86fa098":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["## 0.Going Modular\n","In this lab we are going to convert custom data make them modular"],"metadata":{"id":"piLfCL_erICL"}},{"cell_type":"markdown","source":["### 0.1Importing data"],"metadata":{"id":"nFf3Ve4nB_3q"}},{"cell_type":"code","source":["import os\n","import requests\n","import zipfile\n","from pathlib import Path"],"metadata":{"id":"SPdkG3UA1WXY","executionInfo":{"status":"ok","timestamp":1719678295146,"user_tz":-345,"elapsed":626,"user":{"displayName":"Sk Magar","userId":"03719210364191846869"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["p = Path('.')\n","[x for x in p.iterdir() if x.is_dir()]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w8U_AY-i1WU4","executionInfo":{"status":"ok","timestamp":1719678296783,"user_tz":-345,"elapsed":984,"user":{"displayName":"Sk Magar","userId":"03719210364191846869"}},"outputId":"b448921e-177c-4156-f5cc-41abc44e987d"},"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[PosixPath('.config'),\n"," PosixPath('data'),\n"," PosixPath('going_modular'),\n"," PosixPath('sample_data')]"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["# Setup path to data folder\n","data_path = Path('data/')\n","image_path = data_path / \"pizza_steak_sushi\"\n","\n","# If the image folder doesn't exist, download it and prepare it...\n","if image_path.is_dir():\n","  print(f\"{image_path} already exist. Exit downloading\")\n","else:\n","  print(f\"Creating image folder at {image_path}\")\n","  image_path.mkdir(parents=True, exist_ok=True)\n","\n","# Download pizza, steak, sushi data\n","with open(data_path / \"pizza_steak_sushi.zip\",\"wb\") as f:\n","  request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n","  print('Downloading pizza steak and sushi')\n","  f.write(request.content)\n","\n","# Unzip pizza, steak, sushi data\n","with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n","  print(\"unzipping file\")\n","  zip_ref.extractall(image_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gs5JrYhq1WTF","executionInfo":{"status":"ok","timestamp":1719678296786,"user_tz":-345,"elapsed":61,"user":{"displayName":"Sk Magar","userId":"03719210364191846869"}},"outputId":"b0c86dd0-1121-450f-ea75-96d989ec8731"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["data/pizza_steak_sushi already exist. Exit downloading\n","Downloading pizza steak and sushi\n","unzipping file\n"]}]},{"cell_type":"code","source":["# Remove zip file\n","os.remove(data_path / \"pizza_steak_sushi.zip\")"],"metadata":{"id":"JCuvUUUK1WQi","executionInfo":{"status":"ok","timestamp":1719678296787,"user_tz":-345,"elapsed":56,"user":{"displayName":"Sk Magar","userId":"03719210364191846869"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["#set up training and testing path\n","train_dir = image_path / \"train\"\n","test_dir = image_path / \"test\"\n","\n","train_dir, test_dir"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tJRfvCeqss1v","executionInfo":{"status":"ok","timestamp":1719678296787,"user_tz":-345,"elapsed":55,"user":{"displayName":"Sk Magar","userId":"03719210364191846869"}},"outputId":"05149835-140f-4b4e-f7f4-3b34be28e5e4"},"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(PosixPath('data/pizza_steak_sushi/train'),\n"," PosixPath('data/pizza_steak_sushi/test'))"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["#transformation\n","from torchvision import transforms\n","\n","data_transform = transforms.Compose([\n","    transforms.Resize(size=(64, 64)),\n","    transforms.ToTensor()\n","])\n","data_transform"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"84y7up67tyeA","executionInfo":{"status":"ok","timestamp":1719678296788,"user_tz":-345,"elapsed":52,"user":{"displayName":"Sk Magar","userId":"03719210364191846869"}},"outputId":"f364ed36-4428-48e8-da06-b87c00212fd6"},"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Compose(\n","    Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=True)\n","    ToTensor()\n",")"]},"metadata":{},"execution_count":49}]},{"cell_type":"markdown","source":["## 1.Create datasets and dataloaders\n","* we are using magic command `%%writefile` this convert code to script\n","* we are writing docstring in Google python docstring style"],"metadata":{"id":"s_B9Ztja1WOV"}},{"cell_type":"code","source":["os.makedirs('going_modular', exist_ok=True)"],"metadata":{"id":"_pjN9EVNrY3O","executionInfo":{"status":"ok","timestamp":1719678296788,"user_tz":-345,"elapsed":49,"user":{"displayName":"Sk Magar","userId":"03719210364191846869"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["%%writefile going_modular/data_setup.py\n","\"\"\"\n","contain functionality for creating pytorch DataLoaders for\n","image classification data.\n","\"\"\"\n","import os\n","\n","from torchvision import datasets,transforms\n","from torch.utils.data import DataLoader\n","\n","NUM_WORKER = os.cpu_count()\n","\n","def create_dataloaders(train_dir,\n","                      test_dir,\n","                      transform,\n","                      batch_size: int,\n","                      num_worker: int=NUM_WORKER):\n","  '''Creating training and testing dataloaders\n","\n","  take training directory and testing directory path and turn them into\n","  pytorch dataset and finally pytorch dataloaders\n","\n","  Args:\n","    train_dir: path to training directory\n","    test_dir: path to testing directory\n","    transform: torchvision transform-> to apply in training and testing data\n","    batch_size: no of sample in per batch in each dataloader\n","    num_worker: no of workers per dataloader\n","\n","  Returns:\n","    A tuple of (train_dataloader, test_dataloader, class_names)\n","    where `class_names` is list of target label\n","\n","    Example Usage:\n","      train_dataloader, test_dataloader, clss_names = \\\n","        = create_dataloaders(train_dir= path/to/train_dir,\n","                            test_dir= path/to/test_dir,\n","                            transform= some_transformation,\n","                            batch_size= 32,\n","                            num_worker= 4)\n","\n","  '''\n","\n","  #take and transform data aka `ImageFolder`\n","  train_data = datasets.ImageFolder(train_dir, transform=transform)\n","  test_data = datasets.ImageFolder(test_dir, transform=transform)\n","\n","  # get class name\n","  class_names = train_data.classes\n","\n","  # turn image into dataloaders aka `python iterable`\n","  train_dataloader = DataLoader(\n","      dataset=train_data,\n","      batch_size=batch_size,\n","      shuffle=True,\n","      num_workers=num_worker,\n","      pin_memory=True)\n","\n","  test_dataloader = DataLoader(\n","      dataset=test_data,\n","      batch_size=batch_size,\n","      shuffle=False,\n","      num_workers=num_worker,\n","      pin_memory=True\n","  )\n","\n","  return train_dataloader, test_dataloader, class_names"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FSEVvY2y1WMw","executionInfo":{"status":"ok","timestamp":1719678296788,"user_tz":-345,"elapsed":49,"user":{"displayName":"Sk Magar","userId":"03719210364191846869"}},"outputId":"234071d1-473f-45d2-8270-df1d07026c56"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting going_modular/data_setup.py\n"]}]},{"cell_type":"code","source":["from going_modular import data_setup\n","\n","train_dataloaders, test_dataloaders, class_name = data_setup.create_dataloaders(\n","    train_dir=train_dir,\n","    test_dir= test_dir,\n","    transform= data_transform,\n","    batch_size= 32\n",")\n","\n","train_dataloaders, test_dataloaders, class_name"],"metadata":{"id":"mZJYYPKY1WKd","executionInfo":{"status":"ok","timestamp":1719678296789,"user_tz":-345,"elapsed":48,"user":{"displayName":"Sk Magar","userId":"03719210364191846869"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"698a934d-7ef9-494b-bb63-7bdd10fc2f88"},"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<torch.utils.data.dataloader.DataLoader at 0x7dd294924580>,\n"," <torch.utils.data.dataloader.DataLoader at 0x7dd294927220>,\n"," ['pizza', 'steak', 'sushi'])"]},"metadata":{},"execution_count":52}]},{"cell_type":"markdown","source":["## 2.Making model builder"],"metadata":{"id":"H-itChOGvsqr"}},{"cell_type":"code","source":["%%writefile going_modular/model_builder.py\n","'''\n","Contain pytorch model code to instantiate a TinyVGG model\n","'''\n","\n","import torch\n","from torch import nn\n","\n","class TinyVGG(nn.Module):\n","  \"\"\"Creates the TinyVGG architecture.\n","\n","  Replicate a TinyVGG architecture from CNN Explainer with little modification\n","\n","  Args:\n","    input_shape: integer indicating no of input channels.\n","    output_shape: integer indicating no of output channels.\n","    hidden_unit: integer indicating no of hidden units.\n","\n","  \"\"\"\n","  def __init__(self,\n","               input_shape: int,\n","               output_shape: int,\n","               hidden_unit: int):\n","    super().__init__()\n","\n","    self.conv_layer_1 = nn.Sequential(\n","        nn.Conv2d(in_channels=input_shape,\n","                  out_channels=hidden_unit,\n","                  kernel_size=3,\n","                  stride=1,\n","                  padding=1),\n","        nn.ReLU(),\n","        nn.Conv2d(in_channels=hidden_unit,\n","                  out_channels=hidden_unit,\n","                  kernel_size=3,\n","                  stride=1,\n","                  padding=1),\n","        nn.ReLU(),\n","        nn.MaxPool2d(kernel_size=2, stride=2)\n","    )\n","\n","    self.conv_layer_2 = nn.Sequential(\n","        nn.Conv2d(in_channels=hidden_unit,\n","                  out_channels=hidden_unit,\n","                  kernel_size=3,\n","                  stride=1,\n","                  padding=1),\n","        nn.ReLU(),\n","        nn.Conv2d(in_channels=hidden_unit,\n","                  out_channels=hidden_unit,\n","                  kernel_size=3,\n","                  stride=1,\n","                  padding=1),\n","        nn.ReLU(),\n","        nn.MaxPool2d(kernel_size=2, stride=2)\n","    )\n","\n","    self.classifier = nn.Sequential(\n","        nn.Flatten(),\n","        nn.Linear(in_features=hidden_unit * 16 * 16, out_features=output_shape)\n","    )\n","\n","  def forward(self, x):\n","    return self.classifier(self.conv_layer_2(self.conv_layer_1(x)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SwrFt5cZwhz6","executionInfo":{"status":"ok","timestamp":1719678296789,"user_tz":-345,"elapsed":44,"user":{"displayName":"Sk Magar","userId":"03719210364191846869"}},"outputId":"e2e051d1-59f9-406d-aca0-45bd4f013523"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting going_modular/model_builder.py\n"]}]},{"cell_type":"code","source":["import torch\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"o9L9IFBCG_yh","executionInfo":{"status":"ok","timestamp":1719678296789,"user_tz":-345,"elapsed":41,"user":{"displayName":"Sk Magar","userId":"03719210364191846869"}},"outputId":"09d1197e-f6b7-42d0-c24f-17118fad403a"},"execution_count":54,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cuda'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":54}]},{"cell_type":"code","source":["from going_modular import model_builder\n","\n","model_0 = model_builder.TinyVGG(input_shape=3, output_shape=len(class_name), hidden_unit=10).to(device)\n","model_0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nv_1VUz1whx7","executionInfo":{"status":"ok","timestamp":1719678296790,"user_tz":-345,"elapsed":39,"user":{"displayName":"Sk Magar","userId":"03719210364191846869"}},"outputId":"6ebc8417-e050-4a35-a12f-aa9904f41cd7"},"execution_count":55,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TinyVGG(\n","  (conv_layer_1): Sequential(\n","    (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU()\n","    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU()\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (conv_layer_2): Sequential(\n","    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU()\n","    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU()\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (classifier): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=2560, out_features=3, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":55}]},{"cell_type":"code","source":["try:\n","  import torchinfo\n","except:\n","  !pip install torchinfo\n","  import torchinfo"],"metadata":{"id":"ljnkgno6whwJ","executionInfo":{"status":"ok","timestamp":1719678296791,"user_tz":-345,"elapsed":37,"user":{"displayName":"Sk Magar","userId":"03719210364191846869"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["from torchinfo import summary\n","\n","summary(model=model_0, input_size=(32, 3, 64, 64))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hb11sDu1whuK","executionInfo":{"status":"ok","timestamp":1719678296791,"user_tz":-345,"elapsed":36,"user":{"displayName":"Sk Magar","userId":"03719210364191846869"}},"outputId":"5445f6ad-24cb-40ab-df52-8e095eb3a858"},"execution_count":57,"outputs":[{"output_type":"execute_result","data":{"text/plain":["==========================================================================================\n","Layer (type:depth-idx)                   Output Shape              Param #\n","==========================================================================================\n","TinyVGG                                  [32, 3]                   --\n","├─Sequential: 1-1                        [32, 10, 32, 32]          --\n","│    └─Conv2d: 2-1                       [32, 10, 64, 64]          280\n","│    └─ReLU: 2-2                         [32, 10, 64, 64]          --\n","│    └─Conv2d: 2-3                       [32, 10, 64, 64]          910\n","│    └─ReLU: 2-4                         [32, 10, 64, 64]          --\n","│    └─MaxPool2d: 2-5                    [32, 10, 32, 32]          --\n","├─Sequential: 1-2                        [32, 10, 16, 16]          --\n","│    └─Conv2d: 2-6                       [32, 10, 32, 32]          910\n","│    └─ReLU: 2-7                         [32, 10, 32, 32]          --\n","│    └─Conv2d: 2-8                       [32, 10, 32, 32]          910\n","│    └─ReLU: 2-9                         [32, 10, 32, 32]          --\n","│    └─MaxPool2d: 2-10                   [32, 10, 16, 16]          --\n","├─Sequential: 1-3                        [32, 3]                   --\n","│    └─Flatten: 2-11                     [32, 2560]                --\n","│    └─Linear: 2-12                      [32, 3]                   7,683\n","==========================================================================================\n","Total params: 10,693\n","Trainable params: 10,693\n","Non-trainable params: 0\n","Total mult-adds (M): 215.86\n","==========================================================================================\n","Input size (MB): 1.57\n","Forward/backward pass size (MB): 26.22\n","Params size (MB): 0.04\n","Estimated Total Size (MB): 27.83\n","=========================================================================================="]},"metadata":{},"execution_count":57}]},{"cell_type":"markdown","source":["## 3.Creating  test fn\n","* train_step() , test_step() fn and combine"],"metadata":{"id":"bmjWRPHZwhpc"}},{"cell_type":"code","source":["%%writefile going_modular/engine.py\n","'''\n","Contain fn for training and testing a pytorch module\n","'''\n","\n","import torch\n","\n","from tqdm.auto import tqdm\n","from typing import List, Dict, Tuple\n","\n","def train_step(model,\n","               dataloaders,\n","               loss_fn,\n","               optimizer,\n","               device) -> Tuple[float, float]:\n","  \"\"\"Train a pytorch model for single epochs\n","\n","  Turn the model to training mode and run through require training\n","  forward pass, loss calculation and optimizer step.\n","\n","  Args:\n","    model: model to be train\n","    dataloaders: train dataloaders\n","    loss_fn: calculate loss\n","    optimizer: optimize the loss\n","    device: which device to train\n","\n","  Returns:\n","    return tuple of train_loss, train_acc\n","\n","  \"\"\"\n","\n","  train_loss, train_acc = 0, 0\n","\n","  model.train()\n","\n","  for X, y in dataloaders:\n","    X, y = X.to(device), y.to(device)\n","    #forward\n","    y_preds = model(X)\n","    #loss\n","    loss = loss_fn(y_preds, y)\n","    train_loss += loss.item()\n","    #optimizer.zero_grad, backpropagation, optimizer.step\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    #accuracy\n","    y_pred_class = torch.argmax(torch.softmax(y_preds, dim=1), dim=1)\n","    train_acc += (y_pred_class == y).sum().item()/len(y_preds)\n","\n","  train_loss /= len(dataloaders)\n","  train_acc /= len(dataloaders)\n","  return train_loss, train_acc\n","\n","\n","def test_step(model,\n","              dataloaders,\n","              loss_fn,\n","              device) -> Tuple[float, float]:\n","  \"\"\"Test a model for single epochs\n","\n","  Turn model to eval mode and perform forward pass and calc loss\n","\n","  Args:\n","    model= model to test\n","    dataloaders= test_dataloders\n","    loss_fn = to calc loss\n","    device= device to perform calc\n","\n","  Returns:\n","    returns tuples of test_loss and test_acc\n","\n","  \"\"\"\n","  test_loss, test_acc = 0, 0\n","\n","  model.eval()\n","  with torch.inference_mode():\n","    for X, y in dataloaders:\n","      X, y = X.to(device), y.to(device)\n","      #forward\n","      y_preds = model(X)\n","      #loss\n","      loss = loss_fn(y_preds, y)\n","      test_loss += loss.item()\n","\n","      acc = torch.argmax(torch.softmax(y_preds, dim=1), dim=1)\n","      test_acc += (acc==y).sum().item()/len(y_preds)\n","\n","  test_loss /= len(dataloaders)\n","  test_acc/= len(dataloaders)\n","\n","  return test_loss, test_acc\n","\n","\n","def train(model,\n","          train_dataloaders,\n","          test_dataloaders,\n","          loss_fn,\n","          optimizer,\n","          epochs,\n","          device) -> Dict[str, List]:\n","  \"\"\"Combine both train_step() and test_step()\n","\n","  Train and Test a model for no of epochs\n","\n","  Args:\n","    model: model to train\n","    train_dataloaders: train_dataloader\n","    test_dataloaders: test_dataloader\n","    loss_fn: calculate the loss\n","    optimizer: minimize the loss\n","    epochs: no of times model should train\n","    device: device where model should train\n","\n","  Return:\n","    return a dictionary of train_loss,train_acc,test_loss,test_acc\n","  \"\"\"\n","\n","  results = {\"train_loss\": [],\n","      \"train_acc\": [],\n","      \"test_loss\": [],\n","      \"test_acc\": []\n","  }\n","\n","  for epoch in tqdm(range(epochs)):\n","\n","    train_loss, train_acc = train_step(\n","        model=model,\n","        dataloaders= train_dataloaders,\n","        loss_fn= loss_fn,\n","        optimizer=optimizer,\n","        device=device\n","    )\n","\n","    test_loss, test_acc = test_step(\n","        model= model,\n","        dataloaders= test_dataloaders,\n","        loss_fn = loss_fn,\n","        device= device\n","    )\n","\n","    # Print out what's happening\n","    print(\n","          f\"Epoch: {epoch+1} | \"\n","          f\"train_loss: {train_loss:.4f} | \"\n","          f\"train_acc: {train_acc:.4f} | \"\n","          f\"test_loss: {test_loss:.4f} | \"\n","          f\"test_acc: {test_acc:.4f}\"\n","    )\n","\n","      # Update results dictionary\n","    results[\"train_loss\"].append(train_loss)\n","    results[\"train_acc\"].append(train_acc)\n","    results[\"test_loss\"].append(test_loss)\n","    results[\"test_acc\"].append(test_acc)\n","\n","  # Return the filled results at the end of the epochs\n","  return results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EzZROJXPwhnB","executionInfo":{"status":"ok","timestamp":1719678296791,"user_tz":-345,"elapsed":32,"user":{"displayName":"Sk Magar","userId":"03719210364191846869"}},"outputId":"b3eb3034-cd69-4619-e817-e1cfa829b21f"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting going_modular/engine.py\n"]}]},{"cell_type":"code","source":["\n","from going_modular.engine import train\n","\n","optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.001)\n","\n","train(model= model_0,\n","      train_dataloaders=train_dataloaders,\n","      test_dataloaders=test_dataloaders,\n","      loss_fn=nn.CrossEntropyLoss(),\n","      optimizer=optimizer,\n","      epochs= 5,\n","      device=device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":414,"referenced_widgets":["e27c0853a2014507b0457678bf8c0e5e","c6e10582d90d48e9b2fad185e7f83950","bb6cbfe3090b496daf921a4f3ec21ede","3cdfce23167b413295333983f36a5691","ef64508ea2fb479b8772047c07104019","0bbdb00cbf734414b6d6c3a2722b54c5","c78188b1cc234641ba1ecddabc2d6d36","0a76524cb7944646a4778887e4b531f0","58efe5116f634f95bc34df834569063e","cf9df38da63248c0af1118b10303d2f0","007f44c18dea4ee192d178d1b86fa098"]},"id":"dn9KB37KHs9y","executionInfo":{"status":"ok","timestamp":1719678301932,"user_tz":-345,"elapsed":5169,"user":{"displayName":"Sk Magar","userId":"03719210364191846869"}},"outputId":"d426a98b-3844-48b8-fb5c-a1073b920580"},"execution_count":59,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/5 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e27c0853a2014507b0457678bf8c0e5e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 1 | train_loss: 1.1038 | train_acc: 0.3047 | test_loss: 1.0987 | test_acc: 0.2604\n","Epoch: 2 | train_loss: 1.0943 | train_acc: 0.4258 | test_loss: 1.0999 | test_acc: 0.2604\n","Epoch: 3 | train_loss: 1.0930 | train_acc: 0.4258 | test_loss: 1.1012 | test_acc: 0.2604\n","Epoch: 4 | train_loss: 1.0929 | train_acc: 0.4258 | test_loss: 1.1024 | test_acc: 0.2604\n","Epoch: 5 | train_loss: 1.1040 | train_acc: 0.3047 | test_loss: 1.1039 | test_acc: 0.2604\n"]},{"output_type":"execute_result","data":{"text/plain":["{'train_loss': [1.1037781536579132,\n","  1.094342589378357,\n","  1.092969685792923,\n","  1.0928970128297806,\n","  1.1040384024381638],\n"," 'train_acc': [0.3046875, 0.42578125, 0.42578125, 0.42578125, 0.3046875],\n"," 'test_loss': [1.0987149477005005,\n","  1.0999411344528198,\n","  1.101176659266154,\n","  1.1024039189020793,\n","  1.10391100247701],\n"," 'test_acc': [0.2604166666666667,\n","  0.2604166666666667,\n","  0.2604166666666667,\n","  0.2604166666666667,\n","  0.2604166666666667]}"]},"metadata":{},"execution_count":59}]},{"cell_type":"markdown","source":["## 4.Saving model"],"metadata":{"id":"0mUGEBIaHs6-"}},{"cell_type":"code","source":["%%writefile going_modular/utils.py\n","\n","\n","import torch\n","from pathlib import Path\n","\n","def save_model(model: torch.nn.Module,\n","               target_dir: str,\n","               model_name: str):\n","  # Create target directory\n","  target_dir_path = Path(target_dir)\n","  target_dir_path.mkdir(parents=True,\n","                        exist_ok=True)\n","\n","  # Create model save path\n","  assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\"), \"model_name should end with '.pt' or '.pth'\"\n","  model_save_path = target_dir_path / model_name\n","\n","  # Save the model state_dict()\n","  print(f\"[INFO] Saving model to: {model_save_path}\")\n","  torch.save(obj=model.state_dict(),\n","             f=model_save_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"obHyOEmfHs4M","executionInfo":{"status":"ok","timestamp":1719678301933,"user_tz":-345,"elapsed":41,"user":{"displayName":"Sk Magar","userId":"03719210364191846869"}},"outputId":"6b8e0d65-6586-4c9e-ab83-43da5bb695c2"},"execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing going_modular/utils.py\n"]}]},{"cell_type":"markdown","source":["## 5.Train,eval and save model"],"metadata":{"id":"LkmTxWFWtqyW"}},{"cell_type":"code","source":["%%writefile going_modular/train.py\n","import os\n","import torch\n","from torch import nn\n","\n","from torchvision import transforms\n","from timeit import default_timer as timer\n","\n","import data_setup, engine, model_builder, utils\n","\n","# hyperparameters\n","EPOCHS = 5\n","BATCH_SIZE = 32\n","HIDDEN_UNITS = 10\n","LEARNING_RATE = 0.001\n","\n","# Setup directories\n","train_dir = \"data/pizza_steak_sushi/train\"\n","test_dir = \"data/pizza_steak_sushi/test\"\n","\n","# Setup device agnostic code\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# Create transforms\n","data_transform = transforms.Compose([\n","                                     transforms.Resize((64, 64)),\n","                                     transforms.ToTensor()\n","])\n","\n","# Create DataLoader's and get class_names\n","train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n","                                                                               test_dir=test_dir,\n","                                                                               transform=data_transform,\n","                                                                               batch_size=BATCH_SIZE)\n","\n","\n","#model\n","model = model_builder.TinyVGG(input_shape=3,\n","                              output_shape=len(class_names),\n","                              hidden_unit=10).to(device)\n","#loss_fn and optimizer\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(params=model.parameters(),\n","                             lr=LEARNING_RATE)\n","\n","start_time = timer()\n","engine.train(model= model,\n","      train_dataloaders=train_dataloader,\n","      test_dataloaders=test_dataloader,\n","      loss_fn=loss_fn,\n","      optimizer=optimizer,\n","      epochs= EPOCHS,\n","      device=device)\n","\n","end_time = timer()\n","print(f\"total time: {end_time - start_time:.3f}\")\n","\n","# Save the model to file\n","utils.save_model(model=model,\n","                 target_dir=\"models\",\n","                 model_name=\"05_going_modular_script_mode_tinyvgg_model.pth\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BDIhDqR7t5yN","executionInfo":{"status":"ok","timestamp":1719678301933,"user_tz":-345,"elapsed":35,"user":{"displayName":"Sk Magar","userId":"03719210364191846869"}},"outputId":"f0030854-417c-462e-f971-4e8697015973"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing going_modular/train.py\n"]}]},{"cell_type":"code","source":["!python going_modular/train.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UgJYkTw0t5vY","executionInfo":{"status":"ok","timestamp":1719678311160,"user_tz":-345,"elapsed":9257,"user":{"displayName":"Sk Magar","userId":"03719210364191846869"}},"outputId":"df8e6398-9790-4bd7-8472-68b72360c5df"},"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["  0% 0/5 [00:00<?, ?it/s]Epoch: 1 | train_loss: 1.1088 | train_acc: 0.3008 | test_loss: 1.1051 | test_acc: 0.1979\n"," 20% 1/5 [00:01<00:05,  1.28s/it]Epoch: 2 | train_loss: 1.1050 | train_acc: 0.2930 | test_loss: 1.1458 | test_acc: 0.1979\n"," 40% 2/5 [00:02<00:03,  1.03s/it]Epoch: 3 | train_loss: 1.0947 | train_acc: 0.3242 | test_loss: 1.1465 | test_acc: 0.2604\n"," 60% 3/5 [00:02<00:01,  1.06it/s]Epoch: 4 | train_loss: 1.1221 | train_acc: 0.4062 | test_loss: 1.1538 | test_acc: 0.2292\n"," 80% 4/5 [00:03<00:00,  1.10it/s]Epoch: 5 | train_loss: 1.0836 | train_acc: 0.5000 | test_loss: 1.1009 | test_acc: 0.2396\n","100% 5/5 [00:04<00:00,  1.08it/s]\n","total time: 4.649\n","[INFO] Saving model to: models/05_going_modular_script_mode_tinyvgg_model.pth\n"]}]}]}